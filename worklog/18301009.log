6.29 
大致分配任务 明确工期与分工 大致了解项目整体需求（其实也没怎么看懂）
解决了之前spark配置失败问题，并尝试任务10 数据清洗(每年某一天的数据)
遇到问题：ValueError:Lengths must match 原因：输入有误，数据集比较对应不匹配（已解决）
遇到问题：从气象局下载的数据集数据从2013年开始就不完整了（以每年6.28日数据清洗为例），导致数据链断掉，最后输出的清洗文件只到2012年。（尚未解决）
6.30(9:00--12:00)
完善任务10，与小组成员合作任务11 12
尝试：使用pandas对原数据集进行清洗，包括最大值最小值和平均值三项（13年后数据不完全 暂时没有数据的地方用空表示）
疑问：不清楚最后要预测的内容具体是什么 如果最高最低平均都要预测的话，可能会有源数据时间不一样长的问题，因为平均气温数据每天都有
尝试：使用spark借助statsmodels对时间数据进行预处理，画出数据图来确定后面模型的选择（未成功 原因不明 还在尝试）
疑问：报错KeyError: 'fData'，尚未解决
学习ARIMA模型，一头雾水，大概明白这个模型可以通过对之前的时间序列进行分析从而达到预测未来数据的作用
模型的选择和参数pdq的确定是此方法应用的重难点
为了确定模型的选择需要对数据进行预处理（正在尝试）